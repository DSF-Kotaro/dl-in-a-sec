{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68GU6g6_QZzu"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modifications Copyright 2019 Tomoaki Masuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHXXNHlvQZzw"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2MX4KdMQZzz"
   },
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet                                                                                                                    # IGNORE_COPYRIGHT: cleared by OSS licensing\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、以下のノートブックを元に日本語訳、一部章立ての再構成、加筆を行いました。https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/images/transfer_learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4tVb8ekQZz2"
   },
   "source": [
    "\n",
    "# 事前学習済みCNN(MobileNet V2)を使った転移学習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dAPVPFoQZz5"
   },
   "source": [
    "\n",
    "このチュートリアルでは、事前学習済みモデルと、その転移学習（ファインチューニング）を使って、犬猫画像の分類を試します。 \n",
    "\n",
    " **事前学習済みモデル**は、通常大規模なデータセット・画像分類タスクで予め学習、保存されたニューラルネットワークです。事前学習済みモデルは、そのまま使うか、または、**転送学習**で特定のタスク用にカスタマイズして使います。\n",
    "\n",
    "転移学習は、直感的に説明すると、大規模かつ十分に汎用的なデータセットで学習したモデルは視覚（画像）に汎用的に使えるので、それをベースに使い各タスク向けのカスタマイズを行うやり方です。これにより、大規模なデータセット・モデルで一から学習せずとも、これらの学習済みモデルが抽出する特徴マップ(feature map)を使えます。\n",
    "\n",
    "このノートブックでは、学習済みモデルをカスタマイズして使う2つの方法を試します。 \n",
    "\n",
    "1.  **学習済みモデルを特徴抽出に使う** ：新規画像から意味のある特徴を抽出するため、既にモデルにより学習済みの表現を使う。事前に学習済みのモデルの上に、最初から学習した新しい分類器を追加するだけで、以前に学習した特徴マップを、新しいデータセット用に再利用できます。このとき、モデル全体を（再）学習しなくて済みます。CNNのベース部分には、画像分類に一般的に役立つ機能がすでに含まれています。ただし、事前トレーニング済みモデルの最後の分類部分は、元の分類タスクに固有のものであり、その後モデルが学習されたクラスのセットに固有のものです。 \n",
    "\n",
    "2.  **学習済みモデルのファインチューニング** ：重みが固定されたモデルベースの最上位レイヤのいくつかを、再度重みを動かせる状態にし、新しく追加された分類レイヤとベースモデルの最終レイヤの両方を学習します。これにより、ベースモデル内の高次の特徴表現を、対象とするタスクにより使いやすくするため「微調整」できます。 \n",
    "\n",
    "ここからは、一般的な機械学習の流れに従って進めます。\n",
    "\n",
    "1. データセットの中身を見て、理解する\n",
    "1. 入力パイプラインを作る（今回はKeras `ImageDataGenerator`を使います）\n",
    "1. モデルを作る\n",
    "  * 事前学習済みモデル（および学習済みの重み）を読み込む\n",
    "  * 分類のためのレイヤを上に積む\n",
    "1. モデルを学習させる\n",
    "1. モデルを評価する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. 環境を準備する\n",
    "\n",
    "必要なライブラリのインストール、インポートを行います。ここではTensorFlow 2.2を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_6eZaJjQZz5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check libraries version\n",
    "print(f'TensorFlow Version: {tf.__version__}')\n",
    "print(f'tf.keras Version: {keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maq2802eQZ0A"
   },
   "source": [
    "\n",
    "## B. データセットを準備する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYXFESx3QZ0B"
   },
   "source": [
    "\n",
    "### 1. データセットをインポートする\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLEXwzz8QZ0D"
   },
   "source": [
    "[TensorFlowデータセット](http://tensorflow.org/datasets)を使って、猫と犬のデータセットを読み込みます。 \n",
    "\n",
    "`tfds`パッケージを使うと、とても簡単に、予め準備されたデータセットを読み込めます。あなた自身の持っているデータセットを使い、TensroFlowでインポートしたい場合は、[画像データのロード](../load_data/images.ipynb)ノートブックをご参照ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLBU7IL6QZ0E"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import tensorflow_datasets as tfds\n",
    "except:\n",
    "  # The tensorflow-datasets module is an external module, so if you don't have it in your environment, you need to pip install it.\n",
    "  !python -m pip install tensorflow-datasets\n",
    "  import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAbKqzS2QZ0H"
   },
   "source": [
    "\n",
    " `tfds.load()`関数はデータセットをダウンロードしてキャッシュし、 `tf.data.Dataset`オブジェクトを返します。このオブジェクトは、データを操作し、モデルに入力するため、強力かつ効率的な方法を提供します。\n",
    "\n",
    " `\"cats_vs_dog\"`はデータセットの分割方法を予め定義していません。 `subsplit()`関数を使って、学習、検証、テストデータセットをそれをそれぞれ80％、10％、10％に分けることにします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzKdGAuXQZ0I",
    "outputId": "60549ebe-9344-4b1d-f2bb-6ee7c0a187a4"
   },
   "outputs": [],
   "source": [
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJazY9C5QZ0N"
   },
   "source": [
    "\n",
    "結果として返される `tf.data.Dataset`オブジェクトは、`(image, label)`ペアを持ちます。 \n",
    "\n",
    "- `画像(image)` は縦横のサイズは可変、各ピクセルは3つのチャンネル（RGB（赤緑青）に対応する3つの数値）を持ちます。\n",
    "- `ラベル(label)` は、対応する画像ごとに、スカラー値を1つ取ります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bE7LUojHQZ0O",
    "outputId": "3d8546df-bf09-4193-b1dd-18a1bb640eb9"
   },
   "outputs": [],
   "source": [
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. データセットの中身を見てみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz0C5EMvQZ0R"
   },
   "source": [
    "\n",
    "トレーニングセットの最初の2つの画像とラベルを表示します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N76KJaclQZ0S",
    "outputId": "5224452e-3546-4cc9-f991-0217ff52b6ea"
   },
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for image, label in raw_train.take(2):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9v_oaO4sQZ0W"
   },
   "source": [
    "\n",
    "### C. データセットを前処理する\n",
    "\n",
    "画像に前処理を施すために `tf.image`モジュールを使います。 \n",
    "\n",
    "画像を、予め決められた入力サイズ（160x160）に合わせてサイズ変更し、各ピクセルのチャンネル（もともとは0から255の間）を、`[-1,1]`の範囲におさまるように変換します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fn0lPSmfQZ0W"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 160 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/127.5) - 1\n",
    "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6QLvr3mQZ0a"
   },
   "source": [
    "\n",
    " `map()` 関数を使って、データセットの各項目にこの関数を適用します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPI4latWQZ0b"
   },
   "outputs": [],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxdsksGRQZ0e"
   },
   "source": [
    "\n",
    "データセットをシャッフルして、バッチにまとめます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdF9Rv1NQZ0f"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M8gzrWuQZ0i"
   },
   "outputs": [],
   "source": [
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KXxwzH2QZ0k"
   },
   "source": [
    "\n",
    "データセットのバッチを調べます。（1ピクセルにつきRGB3種類の数値を持つ、160x160の画像が、32個束ねられたバッチが作られています）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfTob6fMQZ0k",
    "outputId": "eb53730c-e92f-467d-d5a0-3e49555e79e2"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "  pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# その1 - 学習済みモデルを特徴抽出に使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6t0kDMgQZ0o"
   },
   "source": [
    "\n",
    "## D. モデルを作成する\n",
    "\n",
    "### 1. 学習済みモデルからベースモデルを作る\n",
    "\n",
    " Googleが開発した**MobileNet V2**から、ベースとなるモデルを作ります。このモデルは、ImageNet（1.4M画像と1000クラスのWeb画像からなる大規模データセット）で事前学習されています。 ImageNetは研究用の学習データセットです。 `jackfruit（ジャックフルーツ）`や`syringe（注射器）`などのカテゴリを含むなど偏りがないとも言えません。しかし、この知識ベースは、我々のデータセットで犬猫分類をするのに役立ちます。 \n",
    "\n",
    "まず、MobileNet V2のどの層を特徴抽出に使うか選びます。明らかに、最後の分類レイヤ（または「一番上」のレイヤ - 機械学習モデルを図示するとき、ほとんどの場合は下から上に層を積み上げるよう描くため）はあまり役に立ちません。代わりに、`Flatten` 操作直前のレイヤを使うという、一般的な方法に従います。この層は「ボトルネック層」と呼ばれます。ボトルネック層の抽出する特徴は、最終層/最上層と比較しても、汎用性が高いといわれます。 \n",
    "\n",
    "まず、ImageNetで学習済みの重みをロードしたMobileNet V2モデルを呼び出し（インスタンス化し）ます。 **include_top = False**引数を指定すると、一番上の分類レイヤを除いたモデルが読み込まれます。これは、特徴抽出のために使うときに便利です。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfF8u4saQZ0o",
    "outputId": "6bc2bf23-dc04-4d9d-b950-305787a5d918"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False, \n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQQL7MMyQZ0r"
   },
   "source": [
    "\n",
    "この特徴抽出は、`160x160x3`の画像から、`5x5x1280`の特徴マップを取り出します。バッチの例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XMvVzmMQZ0s",
    "outputId": "c77f9a83-e613-42ef-94db-5a69fb87f567"
   },
   "outputs": [],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RV0a4rsQZ0u"
   },
   "source": [
    "\n",
    "### 2. 学習済みモデルを特徴抽出に使う\n",
    "\n",
    "前の手順で作成した畳み込みニューラルネットワーク（CNN）のベース部分の重みを固定し、それを特徴抽出に使います。その上に分類器を積み上げ、その分類レイヤを学習させます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3g_H2stbQZ0w"
   },
   "source": [
    "\n",
    "#### 2.1 CNNベース部分の重みを固定する\n",
    "\n",
    "モデルをコンパイルして学習を始める前に、CNNベース部分の重みを固定することが大事です。それ（凍結する、フリーズするとも呼びます）をすることで（または`layer.trainable = False` と設定する）、学習中に対象レイヤの重みが更新されなくなります。 MobileNet V2には多くのレイヤーがあります。モデル全体のtrainableフラグを`False`設定すると、全レイヤーの重みが更新されなくなります。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-958K7iYQZ0w"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNUxyRHDQZ0y",
    "outputId": "0db4e582-c08d-4994-97f6-815c5d067c17"
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uEJwHpCQZ02"
   },
   "source": [
    "\n",
    "#### 2.2 分類ヘッドを追加する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mSCq9iVQZ03"
   },
   "source": [
    "\n",
    "特徴ブロックから予測を生成するため、 `tf.keras.layers.GlobalAveragePlloing2d`レイヤを使って、 `5x5`ごとに平均化とプーリングを行い、特徴を1画像あたり1280要素を持つ1次元ベクトルに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8h8d7HdQZ03",
    "outputId": "bbdecbd8-403e-42af-f3a2-8f12b4f1aa56"
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2zfpsn1QZ06"
   },
   "source": [
    "\n",
    "これらの特徴を、 `tf.keras.layers.Dense`レイヤを通して、画像ごとに単一の予測に変換します。この予測は`logit`または生の予測値として扱われるため、ここでは活性化関数は使いません。正は `class 1`、負は `class 0` を予測します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xj8L4kuFQZ06",
    "outputId": "5ddc68cf-a1cd-4342-9f69-67db65278991"
   },
   "outputs": [],
   "source": [
    "prediction_layer = keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lEeQEA15QZ09"
   },
   "source": [
    "\n",
    "そして、`tf.keras.Sequential` を使って、特徴抽出部分とこれら2つのレイヤーを連結・積み上げます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nh7jzkfEQZ09"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLdecKrDQZ0_"
   },
   "source": [
    "\n",
    "### 3. モデルをコンパイルする\n",
    "\n",
    "訓練する前にモデルをコンパイルする必要があります。 2クラス分類のため、バイナリクロスエントロピー損失を使います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVYLHdMHQZ1A"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X32MxFhcQZ1D",
    "outputId": "18aae2ce-6346-48db-c9de-62cc59ad6f9e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFKTXrISQZ1G"
   },
   "source": [
    "\n",
    " MobileNetの2.5Mパラメータは固定されました。ただし、まだDenseレイヤには1.2Kの*学習可能*なパラメータがあります。これらは2つの`tf.Variable`オブジェクト、重みとバイアスに分けられます。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwNfajcsQZ1H",
    "outputId": "73e9ce4d-e1ee-4e0e-d6d9-0f7f72047a76"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiZfGrM7QZ1K"
   },
   "source": [
    "\n",
    "## E. モデルを学習させる\n",
    "\n",
    " 10エポックで、〜96％程度の精度まで学習が進みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k0X_wSWUQZ1O",
    "outputId": "64b96766-5285-41d3-ad7b-ff71b9bd05b2"
   },
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "validation_steps = 20\n",
    "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWcSEUueQZ1R",
    "outputId": "0e50af1d-84ac-43f0-a2e2-bd9cd8b1efa8"
   },
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-88YWSrxQZ1T",
    "outputId": "0a6a274f-a694-4863-90cf-f7a3ba054bbf"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GLqpgDjQZ1V"
   },
   "source": [
    "\n",
    "### 1. 学習曲線を確認する\n",
    "\n",
    " MobileNet V2基本モデルを固定の特徴抽出器として使った場合の、学習曲線と検証の精度/損失を見てみましょう。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0AiQXrtQZ1W",
    "outputId": "ff347133-e82e-4fd0-aeec-3246cb434b31"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-iHkJJiQZ1Y"
   },
   "source": [
    "\n",
    "注：検証時の精度・損失（メトリクス）が学習時の精度・損失より明らかに優れている理由の一つは、 `tf.keras.layers.BatchNormalization` や`tf.keras.layers.Dropout` などのレイヤが学習中の精度に影響を与えるためです。これらは、検証損失の計算時は使われません。 \n",
    "\n",
    "上記ほどではないものの、学習時の精度・損失はエポックの平均を報告し、検証時はエポックの後に評価されるため、検証時の精度・損失は、学習時よりもやや長く学習しモデルに基づくものです。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# その2 - 学習済みモデルのファインチューニング\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-x3I2c1QZ1Z"
   },
   "source": [
    "先の `学習済みモデルを特徴抽出に使う` では、MobileNet V2のベースモデル上に数層を学習させるだけでした。事前学習済みモデルの重みは、学習中には**更新されませんでした** 。 \n",
    "\n",
    "さらに精度を向上させる方法に、追加した分類器のトレーニングと並行し、事前学習済みモデルの最上位層の重みを学習（または「ファインチューニング」）することがあげられます。学習を通して、汎用的な特徴マップから、特に目的のデータセットに関連付けられた特徴抽出のため、重みが調整されます。 \n",
    "\n",
    "注：この場合もまず先に、事前学習済みモデルを `non-trainable（重みを固定）` に設定し、最上位の分類器を学習します。事前学習済みモデル上に、ランダムに初期化された分類器を追加して全レイヤの学習を同時に始めると、（分類器からのランダムな重みのために）勾配の更新の大きさが大きすぎてしまいます。それにより、せっかく事前学習で得た重みが忘れられて（消し飛んで）しまいます。\n",
    "\n",
    "また、MobileNetモデル全体ではなく、少数の最上位レイヤをファインチューニング対象とすると良いでしょう。多くの畳み込みネットワークでは、層が上に行くほど、より特化した機能を持ちます。最初の数層は、様々な種類の画像に共通の、単純・汎用的な特徴を学びます。上に行くにつれて、特徴抽出は、モデルが学習に用いたデータセット特有のものになります。ファインチューニングの目的は、学習済みの汎用的な部分を上書きするのではなく、これらのデータセットに特化した特徴抽出を、新しいデータセットで使えるように調整することです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. モデルを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElxjFvgqQZ1a"
   },
   "source": [
    "\n",
    "### 1. モデルの最上層を解凍する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5agPW06QZ1c"
   },
   "source": [
    "\n",
    "あなたがする必要があるのは`base_model`し、最下層を訓練`base_model`することです。次に、モデルを再コンパイルし（これらの変更を有効にするために必要）、トレーニングを再開します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMbX6kb3QZ1d"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rdvmh9dQZ1f",
    "outputId": "5a84f344-d49e-4950-b6fb-4e99ae407847"
   },
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKgJrSL5QZ1j"
   },
   "source": [
    "\n",
    "### 2. モデルをコンパイルする\n",
    "\n",
    "通常よりかなり小さな学習率を使い、モデルをコンパイルします。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwP6_DMaQZ1k"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29kE4wxWQZ1n",
    "outputId": "2b2156af-8f9e-4cab-e798-214afb0c216a"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ig2avmmQZ1q",
    "outputId": "3b858f87-f7e2-4865-da44-f442f6737006"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KX9OVNFPQZ1t"
   },
   "source": [
    "\n",
    "## E. モデルを学習させる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgME-btxQZ1u"
   },
   "source": [
    "\n",
    "これでより早く学習が収束するようなら、数パーセントの精度向上が見られるかもしれません。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WotVcbUlQZ1v",
    "outputId": "e47d6b50-a4d6-4d5f-a7e4-539daa77b6b3"
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_batches, \n",
    "                         epochs=total_epochs, \n",
    "                         initial_epoch = initial_epochs,\n",
    "                         validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTobNOzoQZ10"
   },
   "source": [
    "\n",
    " MobileNet V2基本モデルの最後の数層をファインチューニングし、その上で分類器を学習す流場合の、学習と検証の精度/損失の学習曲線を見てみましょう。検証の損失は学習の損失よりはるかに大きいので、一定の過学習が見られるかもしれません。 \n",
    "\n",
    "また、新しい学習データセットは比較的小さく、元のMobileNet V2データセットと似ているため、過学習の原因となっているかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIDiqjzNQZ11"
   },
   "source": [
    "\n",
    "微調整後、モデルはほぼ98％の精度に達します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4I8HsILQQZ12"
   },
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04F8TaP6QZ13",
    "outputId": "37376026-cd9b-47e6-aa4e-8c08335b0ea4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], \n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], \n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3-8iK3zQZ16"
   },
   "source": [
    "\n",
    "## まとめ \n",
    "\n",
    "-  **事前学習モデルを特徴抽出に使う** ：小さなデータセットを扱うときは、同じドメイン内のより大きなデータセットでモデルが学習した特徴を使うのが一般的です。事前学習済みモデルをインスタンス化し、その上に全結合層による分類器レイヤを加え実現します。事前学習モデルは重みを固定（凍結）されており、分類器レイヤの重みのみが更新されます。 この場合、CNNのベース部分は各画像の特徴を抽出し、抽出された特徴から、画像のクラスを決定する分類器を学習しました。 \n",
    "\n",
    "-  **事前学習済みモデルのファインチューニング** ：パフォーマンス向上のために、事前学習済みモデルの上位層を、ファインチューニングにより新しいデータセットに適応させられます。この場合、モデルがデータセットに固有の高度な特徴を学習する、重みを調整しました。この手法は通常、学習データセットが大きく、事前学習のデータセットとよく似ている場合に推奨されます。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QYXFESx3QZ0B",
    "aZR0srmeQZ0V",
    "9v_oaO4sQZ0W",
    "TVDP41RUQZ0v",
    "3g_H2stbQZ0w",
    "35zsJCemQZ01",
    "-uEJwHpCQZ02",
    "-wjcOBfxQZ0_",
    "kLdecKrDQZ0_",
    "uUOQp4Z3QZ1K",
    "CiZfGrM7QZ1K",
    "sk-GI0BpQZ1V",
    "_GLqpgDjQZ1V",
    "8TPL8CEQQZ1Z",
    "ElxjFvgqQZ1a",
    "7kpa0IFcQZ1j",
    "SKgJrSL5QZ1j",
    "ydim1uHPQZ1t",
    "KX9OVNFPQZ1t"
   ],
   "name": "転移学習で画像を分類する",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
