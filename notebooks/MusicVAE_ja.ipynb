{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcKmn0uMQn5Q"
   },
   "source": [
    "##### Copyright 2017 Google LLC.\n",
    "\n",
    "##### Modifications Copyright 2019 Tomoaki Masuda.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、以下のノートブックを元に日本語訳、一部章立ての再構成、加筆を行いました。\n",
    "https://colab.research.google.com/notebooks/magenta/music_vae/music_vae.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1R5sFIK6Qn5d"
   },
   "source": [
    "\n",
    "#  MusicVAE: 音楽の長期構造学習のための階層的潜在ベクトルモデル\n",
    "\n",
    "### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n",
    "\n",
    " [MusicVAE](https://g.co/magenta/music-vae)は楽譜の潜在空間を学習し、さまざまなモードを提供します\n",
    "\n",
    "- インタラクティブな音楽制作\n",
    "- 事前分布からの無作為抽出\n",
    "- 既存のシーケンス間の補間\n",
    "- 属性ベクトルを介した既存のシーケンスの操作\n",
    "\n",
    "これらの相互作用の例は以下で実際に試せます。また、作例は、[YouTubeのプレイリスト](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr)で聴くことができます。\n",
    "\n",
    "短いシーケンス（2小節の「ループ」など）は、双方向LSTMエンコーダを使用します。 より長いシーケンスは、新しく提案された階層的LSTMを使います。これは、モデルがより長い構造を学習するのに役立ちます。 \n",
    "\n",
    "また、複数のデコーダを、階層デコーダの最下層のembeddingで学習させることで、楽器間の相互依存関係をモデル化します。\n",
    "\n",
    "[ブログ記事](https://g.co/magenta/music-vae)と[論文](https://goo.gl/magenta/musicvae-paper)に、より詳細の情報があります。 \n",
    "\n",
    "---\n",
    "\n",
    "このノートブックは自己完結型であり、Googleクラウドでネイティブに動作します。\n",
    "\n",
    "独自のモデルをトレーニングしたい場合、[コード](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae)と[チェックポイント](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz)を別々にダウンロードしてローカルで実行します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxundFbqQn5h"
   },
   "source": [
    "\n",
    "## 概要説明\n",
    "\n",
    "1. 非表示のセルをダブルクリックして表示するか、上部のメニューで[表示]&gt; [セクションを展開]を選択します。 \n",
    "1. 各セルの左上隅にある`[ ]`カーソルを合わせ、 `再生`ボタンをクリックして順番に実行します。 \n",
    "1. 生成されたサンプルを聴きます。 \n",
    "1. ノートブックをコピーしたり、コードを修正したり、自分のモデルを訓練したり、自分のMIDIをアップロードしたりするなど、自分だけのものにしましょう。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXHmGUE0Qn5m"
   },
   "source": [
    "\n",
    "## A. 環境を準備する\n",
    "\n",
    "シーケンス合成用のパッケージのインストールが含まれています。数分かかります。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 217002,
     "status": "ok",
     "timestamp": 1546623522420,
     "user": {
      "displayName": "Tomo Masuda",
      "photoUrl": "https://lh5.googleusercontent.com/-xWkmNceNhGQ/AAAAAAAAAAI/AAAAAAAAB60/DG3sdpAeNVE/s64/photo.jpg",
      "userId": "04052575624663243173"
     },
     "user_tz": -540
    },
    "id": "pVS-Hl2kQn5r",
    "outputId": "7647e3a7-e730-42ed-9c24-155bc9092383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying checkpoints and example MIDI from GCS. This will take a few minutes...\n",
      "Installing dependencies...\n",
      "Selecting previously unselected package fluid-soundfont-gm.\n",
      "(Reading database ... 110845 files and directories currently installed.)\n",
      "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
      "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
      "Selecting previously unselected package libfluidsynth1:amd64.\n",
      "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
      "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
      "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "\u001b[31mapache-beam 2.9.0 has requirement pytz<=2018.4,>=2018.3, but you'll have pytz 2018.7 which is incompatible.\u001b[0m\n",
      "Importing libraries and defining some helper functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import cd_fast\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sag_fast import sag\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm, liblinear\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm, liblinear\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm_sparse\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .kd_tree import KDTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/online_lda.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._online_lda import (mean_change, _dirichlet_expectation_1d,\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/graph.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .graph_shortest_path import graph_shortest_path  # noqa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/isotonic.py:11: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._isotonic import _inplace_contiguous_isotonic_regression, _make_unique\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _utils\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _barnes_hut_tsne\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _barnes_hut_tsne\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._criterion import Criterion\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._criterion import Criterion\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._criterion import Criterion\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._criterion import Criterion\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:37: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _k_means\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:38: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._k_means_elkan import k_means_elkan\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hierarchical\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hierarchical\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.py:20: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._dbscan_inner import dbscan_inner\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/hashing.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._hashing import transform as _hashing_transform\n"
     ]
    }
   ],
   "source": [
    "#added on 2020/6/20\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "#@title Setup Environment\n",
    "#@test {\"output\": \"ignore\"}\n",
    "\n",
    "import glob\n",
    "\n",
    "print 'Copying checkpoints and example MIDI from GCS. This will take a few minutes...'\n",
    "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab2/* /content/\n",
    "\n",
    "print 'Installing dependencies...'\n",
    "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
    "!pip install -q pyfluidsynth\n",
    "!pip install -q magenta==0.5\n",
    "\n",
    "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
    "# This is only needed for the hosted Colab environment.\n",
    "import ctypes.util\n",
    "orig_ctypes_util_find_library = ctypes.util.find_library\n",
    "def proxy_find_library(lib):\n",
    "  if lib == 'fluidsynth':\n",
    "    return 'libfluidsynth.so.1'\n",
    "  else:\n",
    "    return orig_ctypes_util_find_library(lib)\n",
    "ctypes.util.find_library = proxy_find_library\n",
    "\n",
    "\n",
    "print 'Importing libraries and defining some helper functions...'\n",
    "from google.colab import files\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def play(note_sequence):\n",
    "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
    "\n",
    "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
    "                assert_same_length=True, temperature=0.5,\n",
    "                individual_duration=4.0):\n",
    "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
    "  note_sequences = model.interpolate(\n",
    "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
    "      temperature=temperature,\n",
    "      assert_same_length=assert_same_length)\n",
    "\n",
    "  print 'Start Seq Reconstruction'\n",
    "  play(note_sequences[0])\n",
    "  print 'End Seq Reconstruction'\n",
    "  play(note_sequences[-1])\n",
    "  print 'Mean Sequence'\n",
    "  play(note_sequences[num_steps // 2])\n",
    "  print 'Start -> End Interpolation'\n",
    "  interp_seq = mm.sequences_lib.concatenate_sequences(\n",
    "      note_sequences, [individual_duration] * len(note_sequences))\n",
    "  play(interp_seq)\n",
    "  mm.plot_sequence(interp_seq)\n",
    "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
    "\n",
    "def download(note_sequence, filename):\n",
    "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
    "  files.download(filename)\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## B. データセットを準備する\n",
    "\n",
    "## C. データセットを前処理する\n",
    "\n",
    "モデルは学習済みで、予め準備したプライマーを元に演奏を生成するため、データセットの準備は不要です。\n",
    "\n",
    "ここから先は、生成する音楽のスタイルごとに、学習済みモデルの取得・生成の試行をそれぞれ試します。\n",
    "\n",
    "- 2小節ドラムモデル\n",
    "- 2小節メロディモデル\n",
    "- 16小節メロディモデル\n",
    "- 16小節トリオモデル\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXXw_uKaQn50"
   },
   "source": [
    "\n",
    "# 2小節ドラムモデル\n",
    "\n",
    "以下は、実験する4つの事前トレーニング済みモデルです。最初の3つは、61のMIDIドラム「ピッチ」を、9つのクラス（ベース、スネア、クローズドハイハット、オープンハイハット、ロータム、ミッドタム、ハイタム、クラッシュシンバル、ライドシンバル）という簡略化し、表現力を落とした出力空間にマッピングします。最後のモデルは、すべての可能なMIDIドラム「ピッチ」を表すために[NADE](http://homepages.inf.ed.ac.uk/imurray2/pub/11nade/)を使用します。 \n",
    "-  **drums_2bar_oh_lokl** ：この*低* KLモデルは、より*リアルな*サンプリングのために学習されました。出力は、ドラムヒットの2 ^ 9の組み合わせのワンホットエンコーディングです。各方向に512ノードの単層双方向LSTMエンコーダ、各層に256ノードの2層LSTMデコーダ、および256次元のZがあります。トレーニング中に0の空きビットが与えられ、0.8の固定ベータ値がありました。 300kステップ後の最終精度は0.73、KLダイバージェンスは11ビットです。 \n",
    "-  **drums_2bar_oh_hikl** ：この*高* KLモデルは、 *再構築と補間の改善*のために学習されました。出力は、ドラムヒットの2 ^ 9の組み合わせのワンホットエンコーディングです。各方向に512ノードの単層双方向LSTMエンコーダ、各層に256ノードの2層LSTMデコーダ、および256次元のZがあります。トレーニング中に96個の空きビットが与えられ、ベータ値は0.2に固定されていました。それは逆シグモイドスケジュールとレート1000でスケジュールされたサンプリングで学習しました。300kの後、ステップの最終的な精度は0.97で、KLダイバージェンスは107ビットです。 \n",
    "-  **drums_2bar_nade_reduced** ：このモデルは9クラスのマルチラベル \"pianoroll\"を出力します。各方向に512のノードを持つ単層双方向LSTMエンコーダ、各層に512のノードを持つ2層のLSTM-NADEデコーダ、128の隠れユニットを持つ9次元のNADE、そして256の次元を持つZがあります。トレーニング中に96の空きビットが与えられ、0.2の固定ベータ値があります。それは逆シグモイドスケジュールとレート1000でスケジュールされたサンプリングで学習しました。300kステップの後、最終的な精度は0.98で、KLダイバージェンスは110ビットです。 \n",
    "-  **drums_2bar_nade_full** ：出力は61クラスのマルチラベル \"pianoroll\"です。各方向に512個のノードを持つ単層双方向LSTMエンコーダ、各層に512個のノードを持つ2層LSTM-NADEデコーダ、および128個の隠れユニットを持つ61次元NADE、そして256次元のZ。トレーニング中に0の空きビットが与えられ、0.2の固定ベータ値があります。それは逆シグモイドスケジュールとレート1000でスケジュールされたサンプリングで学習しました。300kステップの後、最終的な精度は0.90であり、KLダイバージェンスは116ビットです。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. 学習済みモデルを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYNWugmWQn51"
   },
   "outputs": [],
   "source": [
    "#@title Load Pretrained Models\n",
    "\n",
    "drums_models = {}\n",
    "# One-hot encoded.\n",
    "drums_config = configs.CONFIG_MAP['cat-drums_2bar_small']\n",
    "drums_models['drums_2bar_oh_lokl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_small.lokl.ckpt')\n",
    "drums_models['drums_2bar_oh_hikl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_small.hikl.ckpt')\n",
    "\n",
    "# Multi-label NADE.\n",
    "drums_nade_reduced_config = configs.CONFIG_MAP['nade-drums_2bar_reduced']\n",
    "drums_models['drums_2bar_nade_reduced'] = TrainedModel(drums_nade_reduced_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_nade.reduced.ckpt')\n",
    "drums_nade_full_config = configs.CONFIG_MAP['nade-drums_2bar_full']\n",
    "drums_models['drums_2bar_nade_full'] = TrainedModel(drums_nade_full_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_nade.full.ckpt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. モデルを学習する\n",
    "\n",
    "学習済みモデルを使うため不要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R6uj8Oa5Qn5_"
   },
   "source": [
    "\n",
    "## F. 学習済みモデルを評価する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. サンプルを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbuzShv_Qn6B"
   },
   "outputs": [],
   "source": [
    "#@title Generate 4 samples from the prior of one of the models listed above.\n",
    "drums_sample_model = \"drums_2bar_oh_lokl\" #@param [\"drums_2bar_oh_lokl\", \"drums_2bar_oh_hikl\", \"drums_2bar_nade_reduced\", \"drums_2bar_nade_full\"]\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "drums_samples = drums_models[drums_sample_model].sample(n=4, length=32, temperature=temperature)\n",
    "for ns in drums_samples:\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZypRflTQn6E"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download generated MIDI samples.\n",
    "for i, ns in enumerate(drums_samples):\n",
    "  download(ns, '%s_sample_%d.mid' % (drums_sample_model, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vf_hTTQ2Qn6J"
   },
   "source": [
    "\n",
    "### 2. 補間を生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_T_oJao2Qn6K"
   },
   "outputs": [],
   "source": [
    "#@title Option 1: Use example MIDI files for interpolation endpoints.\n",
    "input_drums_midi_data = [\n",
    "    tf.gfile.Open(fn).read()\n",
    "    for fn in sorted(tf.gfile.Glob('/content/midi/drums_2bar*.mid'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTZkvZUOQn6O"
   },
   "outputs": [],
   "source": [
    "#@title Option 2: upload your own MIDI files to use for interpolation endpoints instead of those provided.\n",
    "input_drums_midi_data = files.upload().values() or input_drums_midi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ok9ZAw5NQn6S"
   },
   "outputs": [],
   "source": [
    "#@title Extract drums from MIDI files. This will extract all unique 2-bar drum beats using a sliding window with a stride of 1 bar.\n",
    "drums_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_drums_midi_data]\n",
    "extracted_beats = []\n",
    "for ns in drums_input_seqs:\n",
    "  extracted_beats.extend(drums_nade_full_config.data_converter.to_notesequences(\n",
    "      drums_nade_full_config.data_converter.to_tensors(ns)[1]))\n",
    "for i, ns in enumerate(extracted_beats):\n",
    "  print \"Beat\", i\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YemDbCM_Qn6V"
   },
   "outputs": [],
   "source": [
    "#@title Interpolate between 2 beats, selected from those in the previous cell.\n",
    "drums_interp_model = \"drums_2bar_oh_hikl\" #@param [\"drums_2bar_oh_lokl\", \"drums_2bar_oh_hikl\", \"drums_2bar_nade_reduced\", \"drums_2bar_nade_full\"]\n",
    "start_beat = 0 #@param {type:\"integer\"}\n",
    "end_beat = 1 #@param {type:\"integer\"}\n",
    "start_beat = extracted_beats[start_beat]\n",
    "end_beat = extracted_beats[end_beat]\n",
    "\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "num_steps = 13 #@param {type:\"integer\"}\n",
    "\n",
    "drums_interp = interpolate(drums_models[drums_interp_model], start_beat, end_beat, num_steps=num_steps, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__qgQt8gQn6Y"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download interpolation MIDI file.\n",
    "download(drums_interp, '%s_interp.mid' % drums_interp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ_gF9lzQn6b"
   },
   "source": [
    "\n",
    "# 2小節メロディモデル\n",
    "\n",
    "事前学習済みモデルは、各方向に2048ノードの単層双方向LSTMエンコーダ、各層に2048ノードの3層LSTMデコーダ、および512次元のZから構成されています。このモデルには0フリービットが与えられ、そのベータ値は200kステップにわたって0から0.43まで0.99999の指数関数的速度でアニーリングされました。逆シグモイドスケジュールとレート1000でスケジュールされたサンプリングで学習されました。最終的な精度は0.95であり、KLダイバージェンスは58ビットです。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. 学習済みモデルを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCUPN78LQn6c"
   },
   "outputs": [],
   "source": [
    "#@title Load the pre-trained model.\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/mel_2bar_big.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. モデルを学習する\n",
    "\n",
    "学習済みモデルを使うため不要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSisiPXIQn6f"
   },
   "source": [
    "\n",
    "## F. 学習済みモデルを評価する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. サンプルを生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwGHisTeQn6g"
   },
   "outputs": [],
   "source": [
    "#@title Generate 4 samples from the prior.\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "mel_2_samples = mel_2bar.sample(n=4, length=32, temperature=temperature)\n",
    "for ns in mel_2_samples:\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uqoq2VuPQn6i"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download samples.\n",
    "for i, ns in enumerate(mel_2_samples):\n",
    "  download(ns, 'mel_2bar_sample_%d.mid' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxvqeArkQn6m"
   },
   "source": [
    "\n",
    "### 2. 補間を生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPG21VsIQn6m"
   },
   "outputs": [],
   "source": [
    "#@title Option 1: Use example MIDI files for interpolation endpoints.\n",
    "input_mel_midi_data = [\n",
    "    tf.gfile.Open(fn).read()\n",
    "    for fn in sorted(tf.gfile.Glob('/content/midi/mel_2bar*.mid'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tk9t9t9AQn6o"
   },
   "outputs": [],
   "source": [
    "#@title Option 2: Upload your own MIDI files to use for interpolation endpoints instead of those provided.\n",
    "input_mel_midi_data = files.upload().values() or input_mel_midi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHPTq7KxQn6q"
   },
   "outputs": [],
   "source": [
    "#@title Extract melodies from MIDI files. This will extract all unique 2-bar melodies using a sliding window with a stride of 1 bar.\n",
    "mel_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_mel_midi_data]\n",
    "extracted_mels = []\n",
    "for ns in mel_input_seqs:\n",
    "  extracted_mels.extend(\n",
    "      mel_2bar_config.data_converter.to_notesequences(\n",
    "          mel_2bar_config.data_converter.to_tensors(ns)[1]))\n",
    "for i, ns in enumerate(extracted_mels):\n",
    "  print \"Melody\", i\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTo54axPQn6s"
   },
   "outputs": [],
   "source": [
    "#@title Interpolate between 2 melodies, selected from those in the previous cell.\n",
    "start_melody = 0 #@param {type:\"integer\"}\n",
    "end_melody = 1 #@param {type:\"integer\"}\n",
    "start_mel = extracted_mels[start_melody]\n",
    "end_mel = extracted_mels[end_melody]\n",
    "\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "num_steps = 13 #@param {type:\"integer\"}\n",
    "\n",
    "mel_2bar_interp = interpolate(mel_2bar, start_mel, end_mel, num_steps=num_steps, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xZEkVC4Qn6t"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download interpolation MIDI file.\n",
    "download(mel_2bar_interp, 'mel_2bar_interp.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNpfccJLQn6x"
   },
   "source": [
    "\n",
    "# 16小節メロディモデル\n",
    "\n",
    "事前学習済み階層モデルは、各層各方向に2048ノードを持つ2層双方向LSTMエンコーダ、各層に1024ノードを持つ16ステップ2層LSTM「指揮者」デコーダ、2層LSTM各レイヤに1024個のノードを持つコアデコーダ、および512次元のZから構成されています。256の空きビットが与えられ、ベータ値は0.2に固定されていました。 25kステップ後の最終精度は0.90で、KLダイバージェンスは277ビットです。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. 学習済みモデルを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RP4dLWNwQn6y"
   },
   "outputs": [],
   "source": [
    "#@title Load the pre-trained models.\n",
    "mel_16bar_models = {}\n",
    "hierdec_mel_16bar_config = configs.CONFIG_MAP['hierdec-mel_16bar']\n",
    "mel_16bar_models['hierdec_mel_16bar'] = TrainedModel(hierdec_mel_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/mel_16bar_hierdec.ckpt')\n",
    "\n",
    "flat_mel_16bar_config = configs.CONFIG_MAP['flat-mel_16bar']\n",
    "mel_16bar_models['baseline_flat_mel_16bar'] = TrainedModel(flat_mel_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/mel_16bar_flat.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. モデルを学習する\n",
    "\n",
    "学習済みモデルを使うため不要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. 学習済みモデルを評価する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKSSc1yGQn63"
   },
   "source": [
    "\n",
    "### 1. サンプルを生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZvsBEz5Qn64"
   },
   "outputs": [],
   "source": [
    "#@title Generate 4 samples from the selected model prior.\n",
    "mel_sample_model = \"hierdec_mel_16bar\" #@param [\"hierdec_mel_16bar\", \"baseline_flat_mel_16bar\"]\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "mel_16_samples = mel_16bar_models[mel_sample_model].sample(n=4, length=256, temperature=temperature)\n",
    "for ns in mel_16_samples:\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGf1EA3ZQn65"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download MIDI samples.\n",
    "for i, ns in enumerate(mel_16_samples):\n",
    "  download(ns, '%s_sample_%d.mid' % (mel_sample_model, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5J3F5b1Qn67"
   },
   "source": [
    "\n",
    "### 2. 補間を生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nW4tO1_9Qn68"
   },
   "outputs": [],
   "source": [
    "#@title Option 1: Use example MIDI files for interpolation endpoints.\n",
    "input_mel_16_midi_data = [\n",
    "    tf.gfile.Open(fn).read()\n",
    "    for fn in sorted(tf.gfile.Glob('/content/midi/mel_16bar*.mid'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zB6MIDv1Qn6-"
   },
   "outputs": [],
   "source": [
    "#@title Option 2: upload your own MIDI files to use for interpolation endpoints instead of those provided.\n",
    "input_mel_16_midi_data = files.upload().values() or input_mel_16_midi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8S5OCleQn7A"
   },
   "outputs": [],
   "source": [
    "#@title Extract melodies from MIDI files. This will extract all unique 16-bar melodies using a sliding window with a stride of 1 bar.\n",
    "mel_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_mel_16_midi_data]\n",
    "extracted_16_mels = []\n",
    "for ns in mel_input_seqs:\n",
    "  extracted_16_mels.extend(\n",
    "      hierdec_mel_16bar_config.data_converter.to_notesequences(\n",
    "          hierdec_mel_16bar_config.data_converter.to_tensors(ns)[1]))\n",
    "for i, ns in enumerate(extracted_16_mels):\n",
    "  print \"Melody\", i\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8Utb7fcQn7B"
   },
   "outputs": [],
   "source": [
    "#@title Compute the reconstructions and mean of the two melodies, selected from the previous cell.\n",
    "mel_interp_model = \"hierdec_mel_16bar\" #@param [\"hierdec_mel_16bar\", \"baseline_flat_mel_16bar\"]\n",
    "\n",
    "start_melody = 0 #@param {type:\"integer\"}\n",
    "end_melody = 1 #@param {type:\"integer\"}\n",
    "start_mel = extracted_16_mels[start_melody]\n",
    "end_mel = extracted_16_mels[end_melody]\n",
    "\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "\n",
    "mel_16bar_mean = interpolate(mel_16bar_models[mel_interp_model], start_mel, end_mel, num_steps=3, max_length=256, individual_duration=32, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBpFShRRQn7C"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download mean MIDI file.\n",
    "download(mel_16bar_mean, '%s_mean.mid' % mel_interp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsZcS1WqQn7E"
   },
   "source": [
    "\n",
    "# 16小節「トリオ」モデル（リード、ベース、ドラム） \n",
    "\n",
    " 16小節トリオの2つの事前学習モデルを提示します。階層モデルとフラット（ベースライン）モデルです。 \n",
    "\n",
    "事前学習済み階層モデルは、各層両方向に2048ノードを持つ2層スタックの双方向LSTMエンコーダ、各層に1024ノードを持つ16ステップ2層LSTMの「指揮者」デコーダ、各層の1024ノードを持つ3つ（リード、ベース、ドラム）の2層LSTMコアデコーダ、および512次元のZから構成されています。 1024の空きビットが与えられ、固定ベータ値は0.1でした。それは逆シグモイドスケジュールとレート1000で、スケジュールされたサンプリングで学習しました。50kステップの後、最終的な精度はリード 0.82、ベース 0.87、ドラム 0.90、そしてKLダイバージェンスは1027ビットです。 \n",
    "\n",
    "事前学習済みフラットモデルは、各層両方向に2048ノードを持つ2層スタックの双方向LSTMエンコーダ、各層に2048ノードを持つ3層のLSTMデコーダ、および512次元のZから構成されています。 1024の空きビットが与えられ、固定ベータ値は0.1でした。それは逆シグモイドスケジュールとレート1000で、スケジュールされたサンプリングで学習しました。50kステップの後、最終的な精度はリード 0.67、ベース 0.66、ドラム 0.79、そしてKLダイバージェンスは1016ビットです。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. 学習済みモデルを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4ixkygpQn7F"
   },
   "outputs": [],
   "source": [
    "#@title Load the pre-trained models.\n",
    "trio_models = {}\n",
    "hierdec_trio_16bar_config = configs.CONFIG_MAP['hierdec-trio_16bar']\n",
    "trio_models['hierdec_trio_16bar'] = TrainedModel(hierdec_trio_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/trio_16bar_hierdec.ckpt')\n",
    "\n",
    "flat_trio_16bar_config = configs.CONFIG_MAP['flat-trio_16bar']\n",
    "trio_models['baseline_flat_trio_16bar'] = TrainedModel(flat_trio_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/trio_16bar_flat.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. モデルを学習する\n",
    "\n",
    "学習済みモデルを使うため不要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. 学習済みモデルを評価する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqWiSjp5Qn7G"
   },
   "source": [
    "\n",
    "### 1. サンプルを生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y01hsUMDQn7H"
   },
   "outputs": [],
   "source": [
    "#@title Generate 4 samples from the selected model prior.\n",
    "trio_sample_model = \"hierdec_trio_16bar\" #@param [\"hierdec_trio_16bar\", \"baseline_flat_trio_16bar\"]\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "\n",
    "trio_16_samples = trio_models[trio_sample_model].sample(n=4, length=256, temperature=temperature)\n",
    "for ns in trio_16_samples:\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bea07kpWQn7I"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download MIDI samples.\n",
    "for i, ns in enumerate(trio_16_samples):\n",
    "  download(ns, '%s_sample_%d.mid' % (trio_sample_model, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6GYfGXZQn7K",
    "toc-hr-collapsed": true
   },
   "source": [
    "\n",
    "### 2. 補間を生成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EyzwvUbQn7M"
   },
   "outputs": [],
   "source": [
    "#@title Option 1: Use example MIDI files for interpolation endpoints.\n",
    "input_trio_midi_data = [\n",
    "    tf.gfile.Open(fn).read()\n",
    "    for fn in sorted(tf.gfile.Glob('/content/midi/trio_16bar*.mid'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbHHqQ8CQn7N"
   },
   "outputs": [],
   "source": [
    "#@title Option 2: Upload your own MIDI files to use for interpolation endpoints instead of those provided.\n",
    "input_trio_midi_data = files.upload().values() or input_trio_midi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPYfz8jdQn7P"
   },
   "outputs": [],
   "source": [
    "#@title Extract trios from MIDI files. This will extract all unique 16-bar trios using a sliding window with a stride of 1 bar.\n",
    "trio_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_trio_midi_data]\n",
    "extracted_trios = []\n",
    "for ns in trio_input_seqs:\n",
    "  extracted_trios.extend(\n",
    "      hierdec_trio_16bar_config.data_converter.to_notesequences(\n",
    "          hierdec_trio_16bar_config.data_converter.to_tensors(ns)[1]))\n",
    "for i, ns in enumerate(extracted_trios):\n",
    "  print \"Trio\", i\n",
    "  play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xELJxyiAQn7Q"
   },
   "outputs": [],
   "source": [
    "#@title Compute the reconstructions and mean of the two trios, selected from the previous cell.\n",
    "trio_interp_model = \"hierdec_trio_16bar\" #@param [\"hierdec_trio_16bar\", \"baseline_flat_trio_16bar\"]\n",
    "\n",
    "start_trio = 0 #@param {type:\"integer\"}\n",
    "end_trio = 1 #@param {type:\"integer\"}\n",
    "start_trio = extracted_trios[start_trio]\n",
    "end_trio = extracted_trios[end_trio]\n",
    "\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "trio_16bar_mean = interpolate(trio_models[trio_interp_model], start_trio, end_trio, num_steps=3, max_length=256, individual_duration=32, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbiBzVoMQn7S"
   },
   "outputs": [],
   "source": [
    "#@title Optionally download mean MIDI file.\n",
    "download(trio_16bar_mean, '%s_mean.mid' % trio_interp_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "iXdNIJLlQn6H",
    "c8QaUj1VQn6e",
    "Pt7u84aVQn6l",
    "ZjM_qVORQn62",
    "ovDOLsPxQn66",
    "LXnbXQLaQn7G",
    "1JZ9xqX_Qn7K"
   ],
   "name": "MusicVAEで作曲する",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}